
 \section{Testing}

Testing is one of the oldest forms of software defect removal. It has been the most important category of defect removal since the beginning of the software industry, and in many cases even today, it is the only defect removal activity used. Several aspects of testing is covered widely in literature such as testing itself, test case design, test libraries and others. There are also a variety of standards and certifications offered by several companies and groups. Considering the penetration and importance of testing, there is surprisingly low amounts of quantitative data available on testing and test results. Quantitative data in this context means information about numbers of test cases used, numbers of defects found and other information that can be presented in numbers. In addition to the amount of data, the variety of business sizes is not as wide as it could be. The reason for this is that small companies rarely evaluate or benchmark let alone document the results with sufficient precision.

% Definition??

% Quantitive data?? Onko olennaista?


% -Black box / Glass box
% Functional / Nonfunctional
% Automated / Manual
% General / Automatic / Specialized / User
% 
% Testing by developers vs test personnel p.342




%  \begin{itemize}
%  \item Crash, Smoke and Kattava testaus
%  \item ECO: Chapter 5
% \item ROI: Three main activities: Review, process audit and testing
%  \end{itemize}

% Test stage frequency p.289
% 
% Average test stages: Subroutine, unit, function, regression, system, beta test
% Defect removal efficiency for these 6 usually 75%-85%. < 1000fp sometimes >90%
% Truly universal: Subroutine and unit tests (+system test with different names)
% 
% p.291 function points vs test stages
% 

% Relevant testing stages for small applications:
% Subroutine testing
% Unit testing?
% New function testing
% Regression testing


 \subsection{Subroutine Testing}

 Subroutine is a small piece of code that may have only a few lines of code. Testing subroutines is the lowest level of testing introduced by Capers Jones. It is a very informal way of testing and is performed almost spontaneously by compiling and executing a subroutine just created. The goal of testing the subroutines immediately after creating them is to verify the correct behavior of the algorithm before the integration of the algorithm to the larger module or application.

 Subroutine testing is a glass box form of testing. It is used in almost every custom-coded software and over 90\% of defect repairs. The defect removal efficiency is between 25\% and 75\% and in average 55\%. Because subroutine testing is such a natural process and is such an efficient way to prevent defects, it is often omitted in testing literature.

 % p.297
 \subsection{Unit Testing}

 Unit testing is aimed at small code modules ranging from around 100 to 1000 source code statements. Units are tested by executing the new or repaired code. In case of developing new features, also the surrounding modules can be unit tested. The testing is usually run by the developer who wrote the module. This leads to poor data collection lowering the amount of data available for unit testing.

 Unit testing contains often bad test cases which are either false positives or not finding defects. When using unit testing, a significant amount of bad fixes and new bugs are introduced while repairing defects.

 The unit testing is often measured by code coverage, the degree of code a certain test suite covers. Aiming for high code coverage is usually a natural objective for test suites, but sometimes a high cyclomatic complexity of the module under test can prevent achieving high coverage. Modules with complexity under 10 can be tested thoroughly but when complexity raises over 20, the removal efficiency of the unit testing will decrease.

 Unit tests can be executed manually but also automatically using a test runner connected to triggers actuating the testing sequence. The usage of automatized unit tests is becoming more common, while the popularity of Continuous Integration systems increase. These systems can be bound to version control systems allowing the automatic execution of tests whenever the source code changes.

 Unit testing is considered as glass box testing. It is used in over 85\% of projects using waterfall and in over 80\% of defect repairs. Unit testing removes from under 25\% to over 55\% and in average cases around 35\% of defects. Unit testing can benefit from the usage of static analysis, which is in most cases performed before the unit testing. In development of complex systems, unit testing can also benefit from code inspections.

% TDD

 \subsection{New Function Testing}

New function testing is a way of testing in where tests are written for evaluating the correct functionality of new features. These features can be introduced from modification or updating of an existing application. New function testing is often combined with regression testing.

In an entirely new software project, the new function testing is also known as "component testing". This is because usually the subject under test is a work of a group of developers, combining multiple code blocks into a one functioning component in a large system.

Because of the multiple contributors, the testing is frequently executed by separate testing specialists. Major new functions can exceed 10000 statements of source code, or 100 function points, when added to an existing system. Usually the new function testing is aided by a formal testing plan, planned test cases and a full configuration control. New function testing can be both black box and glass box testing. One of the main targets of new function testing are the errors in the interfaces between modules and in the movement of data through the application.

Like with many other testing method, a high complexity of the code can have a negative impact on new function testing. Both the defect removal efficiency and test coverage tend to decrease as the complexity raises. By using mathematical models for designing the test cases, the efficiency level of the testing can be improved without the need for infinite amount of test cases.

New function testing can take advantage of static analysis and formal code inspections. A usual flow with these three begins from the static analysis of the source code, followed by formal code inspections of the most critical parts and finally performing the new function testing. This combination can reach over 99\% in defect removal efficiency, omitting the defects in requirements. Also using regression testing with new function testing can be beneficial to each other.

New function testing is used in over 99\% of new software projects and also in over 99\% of enhancements to legacy applications. The defect removal efficiency is in average 40\% and ranging from under 30\% to over 55\%. 

 \subsection{Regression Testing}

TODO: Tämä on vähän vaikea selitettävä kun oikeastaan regressiotestausta voidaan tehdä kaikilla tasoilla? No niin tietysti tuota new function testiäkin, mutta regression suhteen oikeaa kohtaa tässä on vaikea osoittaa.

Regression testing is a method of testing targeting the opposite of new function testing. In regression testing, the subjects under tests are old functionalities and features. The word "regression", in the context of software development, means an unintentional damage done to existing features while introducing new functionality. Regression testing also aims to make sure the known defects, repaired before the implementation of the new features, don't reappear.

Regression testing can be initiated during the development, when a sufficient amount of modules have been implemented. It continues through the whole development phase and further over to the post-release phase. Preventing the regression damage is very important in the systems already in maintenance phase.

Testing the regression damage is one of the most extensive forms of testing. This is because the evolution of a software application usually consists of multiple releases taking place over the years. With regression testing, the library of available tests continues to grow over the releases. These libraries involve the whole code base. In large systems the code base can even exceed a million lines of code.

Test libraries concerning a big amount of source code are at times problematic. They can have both useless test cases and test cases containing errors in themselves. Studies about these kind of libraries are rare, but an IBM study of a regression test library found both of the aforementioned. These erroneous test cases can raise the testing costs and lower the defect removal efficiency.

Regression testing is usually done in an application under full configuration control. It can be performed by programmers themselves, testing specialists or quality assurance personnel. Regression testing can be black box of glass box testing. Regression testing can benefit from the usage of static analysis tools on the legacy code under change before implementing the changes or refactoring.

High cyclomatic complexity can be harmful to regression testing. Cyclomatic complexity over 20 can lower the test coverage and defect removal efficiency.

Over 95\% of new application development use regression testing. It is used also in over 97\% of legacy application enhancements and in over 85\% of software defect repairs. The defect removal efficiencies can vary from under 25\% to over 45\%. Average defect removal efficiency of regression testing is 45\%.


 \subsection{Integration Testing}

Integration testing is method normally used in relatively large applications having several modules connected to each other. Generally these large applications are over 1000 function points of size. As the name implies, integration testing is testing a number of modules assembled together to form a single software system.

The pace of integration testing is usually more or less steady as the integration tests usually target a single release or build. These builds can come in different cycles depending on the organization and the development practice. The interval between the builds can be for example a month or a week. As an example, Microsoft integrates the software projects in daily basis and thus performs daily integration tests.

Since the number of modules under test can be significant, the test suites can contain significant amounts of test cases. This leads to high amounts of work needed to design the test cases. However, using mathematical test case design methods can produce high test coverages and high defect removal efficiency with relatively small amount of test cases. 

With integration testing, there are in most cases other supportive tools and practices used. Testing is usually done to an application under formal configuration control. Formal defect reporting procedures and test plans, planned test suites and test library support tools are also commonly used with integration testing.

Integration testing can occur as black box or glass box testing. The execution of the testing is the most effective when it is performed by professional testing personnel. Still, in addition to testing specialists, the testing can be performed by the programmers or quality assurance personnel. 

Integration testing can benefit from static analysis, formal inspections and formal development practices. High cyclomatic complexity of over 20 can reduce the efficiency of integration testing. 

Integration testing is rarely used in small, under 100 function point, projects. In these projects only under 10\% of projects use integration testing. In medium size projects, over 1000 function points, integration testing is used in 85\% of projects. Development of large, over 10000 function point systems use integration testing in over 99\% of projects. The defect removal efficiency of integration testing can be from under 35\% to over 65\% averaging 50\%. 

 \subsection{System Testing}

System testing is in most cases the last form of internal testing. After the system testing, the system is usually tested with real customers in field testing or beta testing. 

Formal system testing for large systems is a critical testing stage and can require large teams of professional testing personnel and programmers involved in the development. This kind of large formal system testing can take several months, consisting of repairing the discovered defects and re-testing. The expression "system testing" dates back to large applications in the 10000 function point range. Since then, the term is widely used to describe the final stage of testing of applications any size. 

System testing requires a formal configuration control of the application and usually a formal defect tracking is used. System testing is generally executed using the principles of black box testing, but sometimes there is also glass box type of testing. Testing can be performed by the developers, professional testing specialists or quality assurance personnel. However, when the testing is performed in large companies or for large systems, professional testing specialists performing the tests is the most common case.

If the system under test contains controls over physical devices, the term system testing can include simultaneous testing of the hardware devices. In these cases the group performing the tests can involve other engineering and quality assurance personnel dealing with the hardware.

System testing can become degraded if the system under test contains error-prone modules. These are modules, that encompasses the majority of the existing defects of the system. Error-prone modules can be extremely harmful for large systems and there is a need for continuously analyzing the existence of these. It is often necessary to precisely remove the error-prone modules and rewrite them with better methods.

IBM did a frequency distribution research in the 1970s for customer-reported defects. For several large applications, the distribution of defects was extremely uneven. With one product, there were 425 modules in the application. In this product, 57\% of all reported defects were found in 35 of these modules. No reported defects at all were found for around 300 modules. All of the 35 error-prone modules had no inspections done and the testing was truncated due to schedule pressures. In addition to highly skewed distribution, bad-fix injections for these error-prone modules was higher than 35\%, so fixing every third bug would generate one new bug.

Error-prone modules has been researched by other companies as well and these analyses confirm that these modules are alarmingly common in large applications. These modules have typically a high cyclomatic complexity and thus have reduced test coverage and defect removal efficiency. Repairing these existing modules is difficult and expensive, but preventing creation of new error-prone modules is possible with a combination of formal inspections with pretest static analysis. In the IBM study, inspections were 100\% effective in preventing new error-prone modules. 

System testing can benefit from static analysis and code inspections. IBM studies show that when error-prone modules were removed and inspections were used, the testing costs and schedules decreased by 65\%. Also the customer satisfaction increased by 75\% and development schedules were shortened by 15\%.

System testing is used in over 99\% of systems over 10000 function points. 75\% of projects over 1000 function points and 50\% of projects over 100 function points are using system testing. The defect removal efficiency ranges from under 25\% to over 95\% averaging 55\%.
 
 \subsection{Agile Testing}

Agile testing is a special form of testing and among the newest forms of testing. As Agile development contains embedded users, these users can define the requirements for a sprint or iteration. Embedded users can also define the proper test cases for an iteration. These test cases are primarily black box test cases, where the embedded user defines the functionality under test and the expected behavior.

In the development of larger applications that might have thousands of users, no single user can produce adequate information for gathering the requirements or specification of test cases. In the testing of normal Agile projects, under 1000 function points, the embedded users can provide effective assistance for the specification of test cases. Also the validation of test results can be usually aided by the embedded users.

In a certain type of Agile development, extreme programming, the test cases are developed prior to the implementation of the features. However, this procedure is not present in all Agile development.

Agile testing is used in over 90\% of Agile application development. Defect removal efficiency is in range of under 40\% to over 65\% and in average 50\%. Agile testing can benefit from static analysis and extreme programming testing.